{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the transform to apply to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Create the directory structure if it doesn't exist\n",
        "os.makedirs('./data/cifar10/train', exist_ok=True)\n",
        "os.makedirs('./data/cifar10/test', exist_ok=True)\n",
        "\n",
        "# Download the training dataset\n",
        "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "# Download the testing dataset\n",
        "testset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "# Function to save images to folders\n",
        "def save_images_to_folder(dataset, folder_path):\n",
        "    for i, (image, label) in enumerate(dataset):\n",
        "        class_folder = os.path.join(folder_path, str(label))\n",
        "        os.makedirs(class_folder, exist_ok=True)\n",
        "        image_path = os.path.join(class_folder, f\"{i}.png\")\n",
        "        torchvision.utils.save_image(image, image_path)\n",
        "\n",
        "# Save training images\n",
        "save_images_to_folder(trainset, './data/cifar10/train')\n",
        "# Save testing images\n",
        "save_images_to_folder(testset, './data/cifar10/test')\n",
        "\n",
        "print(\"CIFAR-10 images saved to train and test folders.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dte_fkgtlgB6",
        "outputId": "7dcab644-5a1d-4ec6-f2c4-04f5cdd9b3fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:08<00:00, 19.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 images saved to train and test folders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2NBh4p9pW-m",
        "outputId": "3ef412de-8554-433c-d6d1-0136ec391baf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ni6OEiaypZpc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define image size and batch size\n",
        "img_height, img_width = 32, 32\n",
        "batch_size = 32\n",
        "\n",
        "# Create image data generators\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    './data/cifar10/train',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=(img_height, img_width),\n",
        "    interpolation='nearest',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    './data/cifar10/test',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=(img_height, img_width),\n",
        "    interpolation='nearest',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj-M5PMsp11V",
        "outputId": "9b340cd5-75ac-4622-fa67-c782fcde808d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50000 files belonging to 10 classes.\n",
            "Found 10000 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_ds, epochs=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyTIEP2wp4Pm",
        "outputId": "b4bdd86d-0be9-4407-e1de-80aed6bde3e9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 40ms/step - accuracy: 0.5729 - loss: 1.2269\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b2676d57010>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(f\"Test loss: {loss:.4f}\")\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrZxIGCzp6nQ",
        "outputId": "1d31cfb0-b7d0-47f7-e817-13ac9442fb8a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.5964 - loss: 1.1669\n",
            "Test loss: 1.1955\n",
            "Test accuracy: 0.5860\n"
          ]
        }
      ]
    }
  ]
}